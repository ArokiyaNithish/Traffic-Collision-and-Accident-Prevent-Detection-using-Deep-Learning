<div align="center">

# üö¶Traffic Collision and Accident Prevention Detection using Deep Learning & IOT

### *A Real-Time AI-Powered Road Safety System for Community Welfare*


![Deep Learning](https://img.shields.io/badge/Deep%20Learning-YOLOv8-blue?style=for-the-badge&logo=python)
![OpenCV](https://img.shields.io/badge/OpenCV-Computer%20Vision-green?style=for-the-badge&logo=opencv)
![Python](https://img.shields.io/badge/Python-3.8+-yellow?style=for-the-badge&logo=python)
![IoT](https://img.shields.io/badge/IoT-ESP32%20%7C%20GPS%20%7C%20WiFi-orange?style=for-the-badge&logo=arduino)
![Community Service](https://img.shields.io/badge/Type-Community%20Service%20Project-red?style=for-the-badge)
![Institution](https://img.shields.io/badge/Institution-Vel%20Tech%20University-purple?style=for-the-badge)
![Real Time Public Problem Solution](https://img.shields.io/badge/Real--Time%20Public%20Problem%20Solution-Active-brightgreen?style=for-the-badge)



> üöÄ **This project is titled **"Traffic Collision and Accident Prevention Detection Using Deep Learning (Community Services)"** and focuses on addressing the critical issue of road accidents, particularly on highways, using a deep learning-based system.**


</div>

---

## üìã Table of Contents

- [üìå Abstract](#-abstract)
- [üéØ Objectives](#-objectives)
- [üî¥ Problem Statement](#-problem-statement)
- [‚úÖ Solution & Approach](#-solution--approach)
- [üîß How the Project Works](#-how-the-project-works)
- [üìã Project Pseudocode](#-project-pseudocode)
- [üìê Project Flowchart](#-project-flowchart)
- [üåê IoT Hardware Upgrade](#-iot-hardware-upgrade--from-software-to-smart-edge-device)
- [üí° Impact](#-impact)
- [üõ†Ô∏è Technology Stack](#Ô∏è-technology-stack)
- [üì¶ Libraries & Dependencies](#-libraries--dependencies)
- [üìÅ Project Structure](#-project-structure)
- [üó∫Ô∏è System Architecture & Block Diagram](#Ô∏è-system-architecture--block-diagram)
- [üë• Survey & Community Engagement](#-survey--community-engagement)
- [üìù Survey Questions](#-survey-questions)
- [üìä Survey Analysis](#-survey-analysis)
- [üîÅ Project Phases](#-project-phases)
- [üíª Main Program](#-main-program)
- [üîç Code Analysis](#-code-analysis)
- [üöÄ Installation & Usage](#-installation--usage)
- [üìÅ Project Files](#-project-files)
- [üîè Official Permission & Bona Fide](#-official-permission--bona-fide)
- [üåü Scope of Future Implementation](#-scope-of-future-implementation)
- [ü§ù Open Source Contribution](#-open-source-contribution)
- [üë®‚Äçüíª Team Members & Author](#-team-members--author)
- [üôè Acknowledgements](#-acknowledgements)
- [üìÑ License](#-license)
- [üìö References](#-references)

---

## üìå Abstract

This project is titled **"Traffic Collision and Accident Prevention Detection Using Deep Learning for Community Services"** and focuses on addressing the critical issue of road accidents, particularly on highways, using a deep learning-based system.

A custom **Convolutional Neural Network (CNN) / YOLOv8** model processes video streams in real time, achieving high accuracy in object detection through feature extraction and classification. The system detects vehicles and pedestrians using bounding boxes, calculates vehicle speed, and estimates the distance between objects using the **Euclidean distance formula**. If a high-speed vehicle approaches a potential collision, the system triggers an alert for timely intervention.

Visual feedback including bounding boxes and speed indicators enhances the system's effectiveness. The project ensures **real-time processing, high accuracy, and scalability** ‚Äî providing an innovative and efficient method for improving road safety and community welfare.

> [*click to view Abstract of the Project*](https://drive.google.com/file/d/1T6qck_z0f7EHBrOzNwW9Iln4F77Cx6G1/view?usp=sharing)
---

## üéØ Objectives

- ‚úÖ **Detect vehicles and pedestrians in real-time** using YOLOv8 deep learning model
- ‚úÖ **Calculate proximity** between detected objects using the Euclidean distance formula
- ‚úÖ **Trigger collision warnings** automatically when threshold distance is breached
- ‚úÖ **Deploy IoT hardware** (ESP32-CAM + GPS + Wi-Fi) for real-world highway deployment
- ‚úÖ **Alert emergency services** with GPS-tagged location when collision risk is detected
- ‚úÖ **Conduct community survey** at Redhills, Chennai to validate real-world impact
- ‚úÖ **Scale to smart city** traffic management infrastructure in future phases

---

## üî¥ Problem Statement

Road traffic accidents are one of the most pressing and persistent social challenges faced globally and particularly in developing countries like **India**.

- üáÆüá≥ India alone witnesses more than **400 deaths per day** due to road crashes, according to national reports.
- According to the **World Health Organization (WHO)**, road traffic injuries are the leading cause of death among individuals aged **5‚Äì29 years**, with over **1.3 million fatalities annually**.
- Areas like **Redhills**, a critical junction connecting Chennai with northern districts of Tamil Nadu, face unique challenges due to:
  - Heavy traffic congestion on NH-16, NH-716, and the Outer Ring Road (ORR)
  - Poorly monitored intersections
  - Insufficient traffic management systems
  - Lack of real-time hazard alerts
  - Delayed emergency response times
  - Reliance solely on manual physical patrolling & CCTV without AI integration

> **"Traditional accident detection systems in Redhills are limited to physical patrolling, CCTV surveillance with no AI integration, and public reporting ‚Äî resulting in delayed awareness, prolonged emergency response times, and a lack of real-time data collection."**

This initiative also aligns with **United Nations SDG 11 ‚Äì Sustainable Cities and Communities**, emphasizing the role of smart technologies in urban safety and resilience.

---

## ‚úÖ Solution & Approach

The proposed solution is a **real-time AI-based Traffic Collision and Accident Prevention Alert System** that uses:

1. **YOLOv8 (You Only Look Once) Deep Learning Model** ‚Äî detects vehicles and pedestrians in video frames with high accuracy.
2. **Euclidean Distance Calculation** ‚Äî estimates proximity between detected objects to predict potential collisions.
3. **Real-Time Alert System** ‚Äî triggers visual alerts (bounding boxes + warning text on screen) when a collision risk is detected.
4. **ESP32-CAM Microcontroller** ‚Äî enables edge processing for embedded deployment on highways.
5. **GPS Module** ‚Äî provides precise location tracking of accident zones.
6. **Wi-Fi Communication** ‚Äî enables instant alert transmission to traffic police and emergency responders.

### How It Works

```
Video Input (Camera/Video File)
        ‚Üì
YOLOv8 Object Detection
        ‚Üì
Identify Vehicles & Pedestrians
        ‚Üì
Calculate Euclidean Distance Between Objects
        ‚Üì
Distance < Threshold? ‚Üí ‚ö†Ô∏è Collision Warning Triggered
        ‚Üì
Alert Emergency Services / Traffic Police
```

---

## üîß How the Project Works

The system works by continuously processing a live video stream to detect vehicles and pedestrians, calculating the risk of collision in real time, and triggering alerts when danger is imminent.

### Step-by-Step Working

#### Step 1 ‚Äî Video Input Capture
The system captures a **live video stream** from:
- A connected **webcam** or **IP camera** mounted at a traffic location
- A **pre-recorded traffic video file** for testing
- An **ESP32-CAM module** for embedded edge deployment on highways

Each frame is processed sequentially in real time using **OpenCV**.

üì∫ *Resource:* [OpenCV Video Capture Tutorial](https://www.youtube.com/watch?v=uWP6UjDeZvY&t=39)

#### Step 2 ‚Äî Detect Vehicles with YOLOv8
Each video frame is passed through the **YOLOv8** model:
- Performs **object classification and localization** in a single forward pass
- Produces **bounding boxes** `(x1, y1, x2, y2)` around each detected vehicle
- Only keeps detections with confidence ‚â• **0.4 (40%)**
- Vehicle classes detected: `Car (2)`, `Motorcycle (3)`, `Bus (5)`, `Truck (7)`

üì∫ *Resource:* [Vehicle Detection with YOLOv8](https://www.youtube.com/watch?v=uWP6UjDeZvY&t=39)

#### Step 3 ‚Äî Detect Pedestrians with YOLOv8
Using the same YOLOv8 model, pedestrians (`class 0 = person`) are identified in the frame with their bounding boxes.

üì∫ *Resource:* [Pedestrian Detection with YOLOv8 + DeepSORT](https://www.youtube.com/watch?v=jIRRuGN0j5E)

#### Step 4 ‚Äî Filter Detections by ROI (Region of Interest)
Detections are filtered to only those **within the defined ROI** ‚Äî the specific zone of the road where collision detection is relevant (e.g., a pedestrian crossing or highway merge point).

üì∫ *Resource:* [People Counting in ROI with OpenCV](https://www.youtube.com/watch?v=t61EqN8ZwDQ)
üì∫ *Resource:* [Retail Counter / ROI Zone Tutorial](https://www.youtube.com/watch?v=hAWpsIuem10&t=1519s)

#### Step 5 ‚Äî Calculate Distance Between Bounding Boxes
For every vehicle‚Äìpedestrian pair detected in the ROI, the **Euclidean distance** between their bounding box centers is calculated:

```
distance = ‚àö((cx‚ÇÇ - cx‚ÇÅ)¬≤ + (cy‚ÇÇ - cy‚ÇÅ)¬≤)
```

where `(cx, cy)` is the center point of each bounding box.

üì∫ *Resource:* [Distance Calculation with Ultralytics YOLOv8](https://www.youtube.com/watch?v=LE8am1QoVn4)

#### Step 6 ‚Äî Collision Warning Triggered
If `distance < THRESHOLD (100 pixels)`, a collision risk is flagged:
- ‚ö†Ô∏è **Warning text** is overlaid on the video frame
- Both at-risk objects are highlighted with **red bounding boxes**
- *(IoT upgrade)* **Buzzer** sounds at the roadside unit
- *(IoT upgrade)* **Wi-Fi alert** is transmitted via ESP32 to the police portal
- *(IoT upgrade)* **GPS coordinates** of the incident are included in the alert

#### Step 7 ‚Äî Draw Bounding Boxes & Display
- **Blue boxes** ‚Äî Safe vehicles
- **Green boxes** ‚Äî Pedestrians (safe)
- **Red boxes + ‚ö†Ô∏è text** ‚Äî Collision risk pair
- The annotated frame is displayed in real time via OpenCV window

#### Step 8 ‚Äî Exit & Resource Release
The loop continues until the video ends or the user presses `Q`. Resources are then released:
```python
cap.release()
cv2.destroyAllWindows()
```

---

## üìã Project Pseudocode


```
START

IMPORT necessary libraries (OpenCV, YOLOv8)

LOAD YOLOv8 models for vehicles and pedestrians

INITIALIZE video capture

DEFINE ROI (Region of Interest) coordinates

WHILE video is open:
    CAPTURE current frame

    DETECT vehicles using YOLOv8
        # Tutorial: https://www.youtube.com/watch?v=uWP6UjDeZvY&t=39

    DETECT pedestrians using YOLOv8
        # Tutorial: https://www.youtube.com/watch?v=jIRRuGN0j5E

    FILTER vehicle and pedestrian detections based on ROI
        # Tutorial: https://www.youtube.com/watch?v=t61EqN8ZwDQ

    FOR each vehicle in detected vehicles:
        FOR each pedestrian in detected pedestrians:

            CALCULATE distance between vehicle and pedestrian bounding boxes
                # Tutorial: https://www.youtube.com/watch?v=LE8am1QoVn4

            IF distance < threshold THEN
                TRIGGER collision warning
                # [IoT] Activate Buzzer + LED
                # [IoT] Send Wi-Fi alert via ESP32 with GPS location
            ENDIF

        ENDFOR
    ENDFOR

    DRAW bounding boxes for vehicles (blue) and pedestrians (green)
    IF collision warning THEN
        DISPLAY warning alert on frame (red boxes + text)
    ENDIF

    DISPLAY processed frame

    CHECK for exit condition (e.g., 'q' key)
ENDWHILE

RELEASE video capture
DESTROY all OpenCV windows

END
```

---

## üìê Project Flowchart

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              START                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Import Libraries (OpenCV, YOLOv8)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Load YOLOv8 Models                 ‚îÇ
‚îÇ  (Vehicles + Pedestrians)           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Initialize Video Capture           ‚îÇ
‚îÇ  Define ROI Coordinates             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         Video is Open?              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò
   YES                            NO ‚Üí END
    ‚îÇ
    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Capture Current Frame              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚ñº                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Detect        ‚îÇ  ‚îÇ  Detect           ‚îÇ
‚îÇ Vehicles      ‚îÇ  ‚îÇ  Pedestrians      ‚îÇ
‚îÇ (YOLOv8)      ‚îÇ  ‚îÇ  (YOLOv8)         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Filter Detections by ROI           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  For Each Vehicle + Pedestrian Pair ‚îÇ
‚îÇ  ‚Üí Calculate Euclidean Distance     ‚îÇ
‚îÇ    d = ‚àö((cx‚ÇÇ-cx‚ÇÅ)¬≤+(cy‚ÇÇ-cy‚ÇÅ)¬≤)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚ñº                  ‚ñº
   distance < 100px    distance ‚â• 100px
         ‚îÇ                  ‚îÇ
         ‚ñº                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ‚ö†Ô∏è COLLISION    ‚îÇ  ‚îÇ  Draw Normal     ‚îÇ
‚îÇ WARNING!        ‚îÇ  ‚îÇ  Bounding Boxes  ‚îÇ
‚îÇ Red Boxes +     ‚îÇ  ‚îÇ  Blue = Vehicle  ‚îÇ
‚îÇ Alert Text      ‚îÇ  ‚îÇ  Green = Person  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                    ‚îÇ
         ‚ñº                    ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ [IoT] Buzzer + LED Trigger          ‚îÇ
‚îÇ [IoT] ESP32 Wi-Fi ‚Üí Alert + GPS     ‚îÇ
‚îÇ       ‚Üí Traffic Police Portal       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Display Processed Frame            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚ñº                  ‚ñº
   Press 'Q' ?         More Frames?
         ‚îÇ                  ‚îÇ
         ‚ñº                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      Back to Loop‚Üë
‚îÇ     END      ‚îÇ
‚îÇ cap.release()‚îÇ
‚îÇ destroyAll() ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

![Block Diagram](https://github.com/user-attachments/assets/ce708765-625a-46ba-a78c-af2343efdcb3)

---

### Flowchart Step Explanations

| Step | Description | Resource |
|------|-------------|----------|
| **Start** | Initiates the program | ‚Äî |
| **Import Libraries** | Loads OpenCV and YOLOv8 | [YOLOv8 Docs](https://docs.ultralytics.com) |
| **Load YOLOv8 Models** | Loads vehicle + pedestrian detection models | [YOLOv8 Tutorial](https://www.youtube.com/watch?v=uWP6UjDeZvY&t=39) |
| **Initialize Video Capture** | Sets up video feed from camera / file / ESP32-CAM | [OpenCV Capture](https://docs.opencv.org) |
| **Define ROI** | Specifies the detection zone on the road | [ROI Tutorial](https://www.youtube.com/watch?v=t61EqN8ZwDQ) |
| **Detect Vehicles** | YOLOv8 identifies vehicles in the ROI | [Vehicle Detection](https://www.youtube.com/watch?v=uWP6UjDeZvY&t=39) |
| **Detect Pedestrians** | YOLOv8 identifies pedestrians in the ROI | [Pedestrian Detection](https://www.youtube.com/watch?v=jIRRuGN0j5E) |
| **Filter by ROI** | Removes detections outside the defined zone | [Filtering Detections](https://www.youtube.com/watch?v=t61EqN8ZwDQ) |
| **Calculate Distance** | Euclidean distance between each vehicle-pedestrian pair | [Distance Calculation](https://www.youtube.com/watch?v=LE8am1QoVn4) |
| **Collision Check** | If distance < threshold ‚Üí collision risk | ‚Äî |
| **Trigger Warning** | Red boxes + alert text + IoT buzzer/Wi-Fi/GPS | ‚Äî |
| **Display Frame** | Shows annotated frame in OpenCV window | ‚Äî |
| **Exit** | Release capture, destroy OpenCV windows | ‚Äî |

---

## üåê IoT Hardware Upgrade ‚Äî From Software to Smart Edge Device

The base project concept (from the reference article) was implemented as a **Python-based software system** running on a laptop or PC. This project **upgraded it with full IoT integration** to enable real-world deployment at Redhills highway intersections.

### üîÑ Original Software vs. Our IoT-Upgraded System

| Feature | Original Software System | Our IoT-Upgraded System |
|---------|--------------------------|-------------------------|
| **Processing Device** | Laptop / PC | ESP32-CAM (Edge Device) |
| **Camera Input** | Webcam / Video File | ESP32-CAM Built-in Camera |
| **Alert Output** | Screen warning (OpenCV only) | Screen + Buzzer + LED + Wi-Fi |
| **Location Tracking** | ‚ùå None | ‚úÖ GPS Module (Neo-6M) |
| **Network Connectivity** | ‚ùå Local only | ‚úÖ Wi-Fi (ESP32 built-in) |
| **Emergency Notification** | ‚ùå Manual observation | ‚úÖ Auto-alert to Traffic Police |
| **Power Source** | Mains power (laptop) | Battery-powered (portable) |
| **Deployment Location** | Indoor / Lab only | Outdoor Highway / Junction |

---

### üîå IoT Hardware Components

| Component | Model | Function |
|-----------|-------|----------|
| **Microcontroller** | ESP32-CAM | Edge AI + Wi-Fi + Camera in one module |
| **Camera** | OV2640 (on ESP32-CAM) | Captures live traffic video feed |
| **GPS Module** | Neo-6M / u-blox | Real-time location tracking |
| **Buzzer** | Active Buzzer | Audible alert when collision detected |
| **LED Indicator** | Red LED | Visual alert at the roadside unit |
| **Wi-Fi** | Built-in (ESP32) | Sends alert + GPS to police portal |
| **Power Supply** | 5V Li-ion Battery | Self-contained, portable deployment |

---

### üì° IoT Alert Flow

```
[ESP32-CAM captures live video]
          ‚îÇ
          ‚ñº
[YOLOv8 + Euclidean Distance on PC/Cloud]
          ‚îÇ  Collision Detected!
          ‚ñº
[Collision Signal ‚Üí ESP32 via Wi-Fi]
          ‚îÇ
          ‚îú‚îÄ‚îÄ‚Üí üîä Buzzer / üî¥ LED ‚Äî Instant roadside alert
          ‚îÇ
          ‚îú‚îÄ‚îÄ‚Üí üìç GPS Module reads coordinates
          ‚îÇ         Lat: xx.xxxx  |  Long: xx.xxxx
          ‚îÇ
          ‚îî‚îÄ‚îÄ‚Üí üì° Wi-Fi transmits ALERT + GPS to:
                    ‚Üí Traffic Police Portal
                    ‚Üí Emergency Control Room
                    ‚Üí Mobile Notification
```

---

### üõ†Ô∏è ESP32-CAM Wiring & Setup

```
ESP32-CAM       ‚Üí   Power Supply
   5V           ‚Üí   VCC
   GND          ‚Üí   GND
   GPIO12       ‚Üí   Buzzer (+)
   GPIO13       ‚Üí   LED (+)

GPS Module (Neo-6M)  ‚Üí  ESP32
   TX    ‚Üí  RX (GPIO3)
   RX    ‚Üí  TX (GPIO1)
   VCC   ‚Üí  3.3V
   GND   ‚Üí  GND
```

#### Arduino IDE Libraries for ESP32
```bash
# Install these in Arduino IDE Board Manager / Library Manager:
# - ESP32 Board Package (by Espressif)
# - TinyGPS++ (GPS data parsing)
# - WiFi.h (built-in with ESP32)
# - HTTPClient.h (for sending HTTP alerts)
```

---


## üí° Impact

| Beneficiary | Impact |
|-------------|--------|
| üöó Drivers & Passengers | Real-time collision warnings reduce accident risk |
| üö∂ Pedestrians | Alerts protect pedestrians near high-speed zones |
| üöë Emergency Medical Teams | Accurate GPS-based location alerts for swift response |
| üëÆ Traffic Police | Automated monitoring reduces dependence on manual patrolling |
| üèòÔ∏è Remote/Rural Communities | Affordable, scalable system for accident-prone highways |
| üèôÔ∏è Smart Cities | Data for traffic analysis and identifying high-risk zones |

**Envisioned Long-Term Impact:**
- Potential to save **thousands of lives annually**, especially in rural and highway settings where human surveillance is minimal.
- Collected data can be used for traffic analysis and identifying high-risk zones.
- Serves as a **model for semi-urban and suburban areas** across India.
- Contributes to **SDG 11: Sustainable Cities and Communities**.

---

## üõ†Ô∏è Technology Stack

### Software & AI/ML

| Technology | Version | Purpose |
|-----------|---------|----------|
| **Python** | 3.8+ | Core programming language |
| **YOLOv8 (Ultralytics)** | Latest | Real-time object detection model |
| **OpenCV (cv2)** | ‚â•4.5.0 | Video capture, frame processing & visualization |
| **NumPy** | ‚â•1.21.0 | Mathematical computations |
| **Math (Euclidean)** | Built-in | Distance calculation between detected objects |

### Hardware Components

| Component | Model | Purpose |
|-----------|-------|---------|
| **ESP32-CAM** | AI Thinker | Edge AI microcontroller for on-device processing |
| **Camera Module** | OV2640 | Video feed capture for real-time analysis |
| **GPS Module** | Neo-6M | Precise location tracking of accident zones |
| **Wi-Fi Module** | Built-in (ESP32) | Instant alert transmission to traffic authorities |
| **Buzzer / LED Alerts** | Active Buzzer | Physical alert system at detection point |

### YOLO Classes Detected

| Class ID | Object |
|---------|--------|
| `0` | Person / Pedestrian |
| `2` | Car |
| `3` | Motorcycle |
| `5` | Bus |
| `7` | Truck |

---

## üì¶ Libraries & Dependencies

```bash
# Core ML & Computer Vision
pip install ultralytics
pip install opencv-python
pip install numpy

# Optional: for visualization & analysis
pip install matplotlib
pip install pandas
```

**Or install all at once:**
```bash
pip install ultralytics opencv-python numpy matplotlib pandas
```

**Arduino IDE Libraries for ESP32 IoT:**
```bash
# Install in Arduino IDE Board Manager / Library Manager:
# - ESP32 Board Package (by Espressif)
# - TinyGPS++ (GPS data parsing)
# - WiFi.h (built-in with ESP32)
# - HTTPClient.h (for sending HTTP alerts)
```

---

## üìÅ Project Structure

```
Traffic-Collision-Detection/
‚îÇ
‚îú‚îÄ‚îÄ üìÅ models/                            # ü§ñ YOLOv8 model files
‚îÇ   ‚îú‚îÄ‚îÄ yolov8n.pt                        # YOLOv8 Nano pre-trained weights (download required)
‚îÇ   ‚îú‚îÄ‚îÄ yolov8s.pt                        # YOLOv8 Small weights (optional, higher accuracy)
‚îÇ   ‚îî‚îÄ‚îÄ coco128.yaml                      # COCO dataset config (80 class definitions)
‚îÇ
‚îú‚îÄ‚îÄ üìÅ data/                              # üìÇ COCO class names & configs
‚îÇ   ‚îî‚îÄ‚îÄ coco.names                        # 80 COCO class labels (person, car, bus, truck...)
‚îÇ
‚îú‚îÄ‚îÄ üìÅ Survey Photoes/                    # Field survey photographs
‚îÇ   ‚îú‚îÄ‚îÄ Survey area Redhills.png
‚îÇ   ‚îú‚îÄ‚îÄ Bus Stand.jpg
‚îÇ   ‚îú‚îÄ‚îÄ Highway.jpg
‚îÇ   ‚îî‚îÄ‚îÄ A Geo Tag Group.jpg
‚îÇ
‚îú‚îÄ‚îÄ Traffic Collision Alert System        # üêç Main Python detection program
‚îÇ   using Deep learning.py
‚îÇ
‚îî‚îÄ‚îÄ README.md                             # üìñ This documentation
```

> ‚ö†Ô∏è **Model Files Not Included**: `yolov8n.pt` and `coco128.yaml` are not committed to this repository due to size. Download them as described in [Installation & Usage](#-installation--usage).

---

## üó∫Ô∏è System Architecture & Block Diagram

The system follows an end-to-end pipeline from video capture to alert generation:

```
[Camera / Video Input]
         ‚Üì
[YOLOv8 Deep Learning Model]
    ‚Üô           ‚Üò
[Vehicles]   [Pedestrians]
         ‚Üì
[Bounding Box Extraction]
         ‚Üì
[Euclidean Distance Calculation]
         ‚Üì
[Collision Risk Assessment]
   Threshold < 100 pixels?
         ‚Üì YES
[‚ö†Ô∏è Visual Alert + Bounding Box Highlight]
         ‚Üì
[Transmit Alert ‚Üí ESP32 ‚Üí Wi-Fi ‚Üí Police/Emergency]
```

> üìå **Block Diagram:** See `Block Diagram.jpg` in this repository for the complete visual architecture.

---

## üë• Survey & Community Engagement

To validate the real-world need for this project, our team conducted a comprehensive on-ground survey at **Redhills, Chennai**, a critical accident-prone intersection of:

- üõ£Ô∏è **National Highway 16 (NH-16)**
- üõ£Ô∏è **National Highway 716 (NH-716)**
- üõ£Ô∏è **Outer Ring Road (ORR)**
- üõ£Ô∏è **Chennai‚ÄìThiruvallur High Road (CTH Road)**

### Survey Activities

| Date | Activity | Outcome |
|------|----------|---------|
| 29/11/24 | Initial project planning & requirement analysis | Identified real-time community problem |
| 30/11/24 | Goal & scope definition finalized | Defined challenges in deep learning-based accident prevention |
| 02/12/24 | Sensor research & hardware component selection | Focused on low-cost CNN-based detection solution |
| 04/12/24 | Prototype development | Converted idea to working flowchart model |
| 06/12/24 | Village analysis & community study | Understood day-to-day challenges from traffic collisions |
| 07/12/24 | Survey & geotagged photos | Collected public opinions; examined accident-prone areas |
| 11/12/24 | Survey analysis | Analyzed data on people facing accidents daily |
| 13/12/24 | Meeting with higher officials (Traffic Police) | Proposed idea and obtained official approval & permission |

### Survey Locations
- üìç **Redhills Bus Stand** ‚Äî Interviewed bus drivers about accident incidents
- üìç **Redhills Highway Area** ‚Äî Public survey with residents about real-life accident experiences
- üìç **Redhills Junction** ‚Äî Geotagged field observations

![WhatsApp Image 2026-02-22 at 5 39 58 PM](https://github.com/user-attachments/assets/3494deda-1db8-4ff9-a735-e36c82a03f03)




---



### Survey Google Form
üìä **Survey Excel Analysis:** [View on Google Sheets](https://docs.google.com/spreadsheets/d/1Z7wNAqDuuX8OEwUKVNr_WBi85BpdiTD0RXc-W4SF2e0/edit?usp=sharing)


üì± **Survey QR Code:** 

![Survey QR code](https://github.com/user-attachments/assets/33d1258f-0de1-4d1a-8c16-3576744cc3ce)




---

## üìù Survey Questions

The following questions were asked to Redhills community members, bus drivers, and pedestrians:

1. What do you think are the major causes of traffic accidents in the area of Redhills?
2. How concerned are you about traffic collisions and accidents in your community?
3. Have you ever been involved in or witnessed a traffic accident?
4. How many times did you get involved in a traffic accident? Where? And what type of accident? *(If NO, please type "NA")*
5. Do you believe technology can help reduce traffic collisions and accidents?
6. What do you think about the idea of using a camera and A.I. to detect potential traffic collisions and accidents?
7. Do you follow traffic rules and regulations?
8. Would you participate in road safety awareness programs if organized in your area?
9. Are you aware of traffic collision and accident prevention systems?
10. Do you use safety features like seat belts and helmets regularly?
11. How would you give an overall rating for traffic management in Redhills?
12. How would you give an overall rating for traffic management by police?
13. Did you ever feel traffic congestion near a bus stand or railway station?
14. How useful do you think the real-time alert system (lights, buzzer, notifications) would be in preventing accidents?
15. Do you think road conditions in Chennai need improvement?
16. Do you think traffic signals are working properly and maintained well?
17. Do you think traffic cameras help control traffic?
18. How often do you experience traffic congestion?

[SURVEY QUESTIONS.pdf](https://github.com/user-attachments/files/25466475/SURVEY.QUESTIONS.pdf)


---

## üìä Survey Analysis

Survey data collected from Redhills community members and bus drivers was analyzed and key findings revealed:

- üìå **High accident awareness** ‚Äî Most respondents had witnessed or experienced traffic accidents
- üìå **Strong technology acceptance** ‚Äî Majority believed AI/camera-based systems can reduce accidents
- üìå **Poor traffic signal maintenance** ‚Äî Community reported inadequate traffic signal functioning
- üìå **Need for improvement** ‚Äî Road conditions and traffic management rated low by residents
- üìå **Safety equipment** ‚Äî Mixed compliance with seat belts and helmets
- üìå **Congestion hotspots** ‚Äî Bus stands and highway intersections identified as major congestion points



---

## üîÅ Project Phases

The project followed a structured milestone-based development approach:

```mermaid
timeline
    title Project Development Timeline
    Phase 1 : Planning & Research
            : Analysis of government accident data
            : Literature review on Redhills area
    Phase 2 : Survey & Data Collection
            : Field visits & observations
            : Interviews with community members
            : Geotagged photos collection
    Phase 3 : Model Development
            : YOLOv8/YOLOv4 Tiny model training
            : Custom dataset on traffic scenarios
    Phase 4 : Hardware Integration
            : ESP32-CAM integration
            : On-site testing
    Phase 5 : Field Testing & Feedback
            : Testing at Redhills locations
            : Real-time performance evaluation
```

---

## üíª Main Program

**File:** [`Traffic Collision Alert System using Deep learning.py`](./Traffic%20Collision%20Alert%20System%20using%20Deep%20learning.py)

```python
import cv2
import numpy as np
from ultralytics import YOLO
import math

# Load YOLOv8 model
model = YOLO('yolov8n.pt')  # Use yolov8n.pt or yolov8s.pt

# Classes: 0 = person, 2-7 = vehicles (car, motorcycle, bus, truck)
VEHICLE_CLASSES = [2, 3, 5, 7]
PERSON_CLASS = 0
DISTANCE_THRESHOLD = 100  # Pixel distance for collision warning

# Video capture
cap = cv2.VideoCapture("input_video.mp4")  # Replace with 0 for webcam

def calculate_distance(box1, box2):
    x1, y1 = int((box1[0] + box1[2]) / 2), int((box1[1] + box1[3]) / 2)
    x2, y2 = int((box2[0] + box2[2]) / 2), int((box2[1] + box2[3]) / 2)
    return math.sqrt((x2 - x1)**2 + (y2 - y1)**2)
```

**Key Features of the Program:**
- Loads pretrained **YOLOv8** model for object detection
- Detects vehicles (cars, trucks, buses, motorcycles) and pedestrians from video
- Calculates **Euclidean distance** between each vehicle‚Äìpedestrian pair
- Triggers **‚ö†Ô∏è Collision Warning** on screen when distance < threshold (100 pixels)
- Highlights objects with **color-coded bounding boxes** (Red = collision risk, Blue = vehicle, Green = person)
- Supports both **video file input** and **live webcam feed**

---

## üîç Code Analysis

### Design Decisions

| Decision | Rationale |
|----------|-----------|
| **YOLOv8 over older YOLO versions** | YOLOv8 provides significantly better mAP and speed for real-time detection |
| **Euclidean Distance over IoU** | Simpler to compute per-frame; sufficient for proximity-based collision risk in this use case |
| **ROI Filtering** | Limits detection to the accident-prone zone, reducing false positives from irrelevant objects |
| **100-pixel threshold** | Calibrated for typical camera distances at intersections; adjustable per deployment |
| **ESP32-CAM for edge deployment** | Low-cost (<$10), built-in camera + Wi-Fi, battery operable ‚Äî ideal for highway installations |
| **GPS Neo-6M module** | Wide availability, low cost, and compatible UART interface with ESP32 |
| **Confidence ‚â• 0.4** | Balances detection recall vs. false positives ‚Äî reduces noise without missing real hazards |
| **Color-coded bounding boxes** | Instant visual feedback for human operators monitoring video feeds |

### Algorithm Complexity

| Operation | Complexity | Notes |
|-----------|-----------|-------|
| YOLOv8 Inference | O(1) per frame | Fixed model size; GPU-accelerated |
| Euclidean Distance | O(V √ó P) | V = vehicles, P = pedestrians per frame |
| ROI Filtering | O(N) | N = total detections per frame |
| Total per frame | ~O(V √ó P) | Typically very small N, negligible overhead |

### Script Dependency Map

```
Video Input (Camera / File / ESP32-CAM)
         ‚Üì
OpenCV VideoCapture ‚Üí Frame extraction
         ‚Üì
YOLOv8 Model ‚Üí Vehicle + Pedestrian detection
         ‚Üì
ROI Filter ‚Üí Remove out-of-zone detections
         ‚Üì
Euclidean Distance ‚Üí Per pair calculation
         ‚Üì
Threshold Check ‚Üí Collision warning trigger
         ‚Üì
[IoT] ESP32 Wi-Fi ‚Üí GPS Alert to Police Portal
```

---

## üöÄ Installation & Usage

### Prerequisites

```bash
pip install ultralytics opencv-python numpy
```

### Run the Detection System

```bash
# Clone this repository
git clone https://github.com/your-username/traffic-collision-detection.git
cd traffic-collision-detection

# Install dependencies
pip install ultralytics opencv-python numpy

# Run with a video file
python "Traffic Collision Alert System using Deep learning.py"

# To use webcam instead of video file, change line 15 in the script:
# cap = cv2.VideoCapture(0)  # 0 for default webcam
```

### Controls

| Key | Action |
|-----|--------|
| `Q` | Quit the detection window |

### Output

- Real-time video window: **"Traffic Collision Detection"**
- **Blue boxes** = Detected vehicles
- **Green boxes** = Detected pedestrians
- **Red boxes + ‚ö†Ô∏è Warning text** = Collision risk detected

---

## üìÅ Project Files

| File / Folder | Description |
|---------------|-------------|
| `Traffic Collision Alert System using Deep learning.py` | üêç Main Python deep learning detection program |
| `models/yolov8n.pt` | ü§ñ YOLOv8 Nano pre-trained weights ‚Äî **download required** (see below) |
| `models/yolov8s.pt` | ü§ñ YOLOv8 Small weights (optional ‚Äî higher accuracy, slower) |
| `models/coco128.yaml` | ‚öôÔ∏è COCO dataset configuration file with 80 class definitions |
| `data/coco.names` | üìã COCO class label list (person, car, bus, motorcycle, truck‚Ä¶) |


### üì• Downloading YOLOv8 Weights & COCO Files

```bash
# YOLOv8 weights are auto-downloaded by Ultralytics on first run:
python -c "from ultralytics import YOLO; YOLO('yolov8n.pt')"

# Or download manually:
# yolov8n.pt  ‚Üí https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt
# yolov8s.pt  ‚Üí https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8s.pt
# coco128.yaml ‚Üí included with ultralytics package (ultralytics/cfg/datasets/coco128.yaml)

# Download coco.names (80 class labels):
# https://github.com/pjreddie/darknet/blob/master/data/coco.names
```

| Model | Size | mAP (val) | Speed | Best For |
|-------|------|-----------|-------|----------|
| `yolov8n.pt` | 6.3 MB | 37.3 | Fastest | Edge / ESP32-CAM |
| `yolov8s.pt` | 21.5 MB | 44.9 | Fast | PC / Laptop |
| `yolov8m.pt` | 49.7 MB | 50.2 | Medium | High accuracy |
| `yolov8l.pt` | 83.7 MB | 52.9 | Slower | GPU server |

---

## üîè Official Permission & Bona Fide

This project has received **official permission and bona fide certification** from:

> **M4 ‚Äì Redhills Traffic Police Community**
> Sub Inspector of Police, Redhills Traffic Station

The certificate confirms the authenticity of the community service survey conducted by the project team at Redhills, Chennai.
 

![Bonfide ](https://github.com/user-attachments/assets/e3212ce6-254e-43e7-a43a-cdded8bcc90d)


---

## Working Demo Prototype Video




https://github.com/user-attachments/assets/4ac575ae-9681-4eb6-92ea-2df21690dc21




---
## üåü Scope of Future Implementation

As a **Minor Project** extension, this system can be enhanced with:

| Feature | Description |
|---------|-------------|
| üèôÔ∏è **Smart City Integration** | Connect with traffic signals, surveillance systems, and urban control centers |
| ‚ö° **Edge AI & IoT Devices** | Use low-power edge devices (NVIDIA Jetson Nano, Seeed XIAO ESP32S3) |
| üöó **V2I Communication** | Vehicle-to-Infrastructure direct communication for real-time hazard alerts |
| ü§ñ **Advanced Deep Learning** | 3D object detection, LiDAR, and self-supervised learning for better accuracy |
| üì± **Mobile App Integration** | App for alerts, user reports, and community feedback |
| ‚òÅÔ∏è **Cloud-Based Dashboard** | Monitor traffic trends, accident hotspots, and AI-generated safety recommendations |

---

## ü§ù Open Source Contribution

We warmly welcome contributions from the open source community! Whether it's **bug fixes**, **new models**, **UI improvements**, or **documentation** ‚Äî every contribution helps!

### How to Contribute

```bash
# 1. Fork the repository on GitHub
# 2. Clone your fork
git clone https://github.com/ArokiyaNithish/traffic-collision-detection.git
cd traffic-collision-detection

# 3. Create a feature branch
git checkout -b feature/your-feature-name

# 4. Make changes and commit
git add .
git commit -m "feat: improve collision threshold calibration"

# 5. Push to your fork
git push origin feature/your-feature-name

# 6. Open a Pull Request on GitHub ‚Üí main branch
```

### Contribution Areas

| Area | Good First Issue? | Description |
|------|------------------|-------------|
| üêõ **Bug Fixes** | ‚úÖ Yes | Fix hardcoded paths, edge cases in detection |
| üìä **New Models** | ‚úÖ Yes | Add YOLOv9 / YOLOv10 comparison |
| üåê **UI Improvement** | ‚úÖ Yes | Web dashboard for live alerts |
| üìâ **Visualization** | ‚úÖ Yes | Add detection heatmaps, trajectory plots |
| üß™ **Unit Tests** | ‚úÖ Yes | Add pytest test cases for distance functions |
| üìñ **Documentation** | ‚úÖ Yes | Improve docstrings, add tutorials |
| üîß **Config File** | ‚ö° Medium | Replace hardcoded thresholds with config.yaml |
| ‚òÅÔ∏è **Cloud Deploy** | ‚ö° Medium | Docker containerization + cloud alert server |
| ü§ñ **Advanced AI** | üî• Advanced | Integrate LiDAR, 3D detection, speed estimation |

### Coding Standards

- Follow **PEP 8** style guide
- Add **docstrings** to all functions/scripts
- Write **meaningful commit messages** (use [Conventional Commits](https://www.conventionalcommits.org/))
- Test your changes locally before submitting PR

### Reporting Issues

Please use [GitHub Issues](https://github.com/ArokiyaNithish/traffic-collision-detection/issues) to:
- üêõ Report bugs
- üí° Request features
- ‚ùì Ask questions

---

## üë®‚Äçüíª Team Members & Author

### Project Team

| Name | Roll Number | VTU ID | Role |
|------|-------------|--------|------|
| **Arokiya Nithish J** | 23UEAD0008 | VTU24347 | Lead Developer & ML Engineer |
| **Ishwarya M** | 23UEAD0028 | VTU24428 | Research & Survey Analysis |


**Supervised by:** Dr. A. Sivanesh Kumar, Ph.D. *(Associate Professor)*
**Department:** Artificial Intelligence and Data Science
**Batch No:** 01 | **Academic Year:** 2024‚Äì2025 (Winter Semester)
**Project Code:** 10214AD501

### Lead Author

**Arokiya Nithish J**
- üéì Department of AI & Data Science ‚Äî Vel Tech University
- üíº Domain: Deep Learning | Computer Vision | IoT | Community Service
- üåê GitHub: [@ArokiyaNithish](https://github.com/ArokiyaNithish)
- üíº LinkedIn: [@Arokiya Nithish J](https://www.linkedin.com/in/arokiya-nithishj/)
- üìß Email: arokiyanithishj@gmail.com
- üåê Portfolio: [arokiyanithish.github.io/portfolio/](https://arokiyanithish.github.io/portfolio/)

---

## üìÑ License

> This is an open-source **community service project** released under the MIT License to encourage learning, research, and social impact in road safety systems.
 you are free to use, modify, and distribute this code with attribution.


```
MIT License

Copyright (c) 2026 Arokiya Nithish J

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

```

See [LICENSE](LICENSE) for full details.


---

## üôè Acknowledgements

We express our deepest gratitude to:

- **Col. Prof. Dr. R. Rangarajan** & **Dr. R. Sagunthala Rangarajan** ‚Äî Honorable Founder Chancellor & Foundress President, Vel Tech University
- **Mrs. Rangarajan Mahalakshmi Kishore** ‚Äî Chairperson and Managing Trustee
- **Prof. Dr. Rajat Gupta** ‚Äî Vice Chancellor, Vel Tech University
- **Dr. A. Sivanesh Kumar** ‚Äî Internal Supervisor & Project Guide
- **M4 Redhills Traffic Police Community** ‚Äî For granting permission and bonafide certification
---

## üìö References

1. World Health Organization (WHO). *Global Status Report on Road Safety.*
2. Ministry of Road Transport and Highways, India. *Road Accidents in India.*
3. Redmon, J., et al. *"You Only Look Once: Unified, Real-Time Object Detection."* IEEE CVPR, 2016.
4. Ultralytics. *YOLOv8 Documentation.* https://docs.ultralytics.com
5. United Nations. *Sustainable Development Goal 11 ‚Äì Sustainable Cities and Communities.*
6. Smith. *"AI Collision Alert: Enhancing Pedestrian Safety on Smart Streets."* Medium, Aug 25, 2024. https://medium.com/@asbmerin/xxxx-24d8ab2f3579
7. MDPI. *"Using Video Analytics to Improve Traffic Intersection Safety and Performance."* https://www.mdpi.com/2624-8921/4/4/68
8. MDPI Electronics. *"NAVIBox: Real-Time Vehicle‚ÄìPedestrian Risk Prediction System in an Edge Vision Environment."* https://www.mdpi.com/2079-9292/12/20/4311
9. Jiao, Y. *Two-Dimensional-Time-To-Collision (GitHub).* https://github.com/Yiru-Jiao/Two-Dimensional-Time-To-Collision
10. Roboflow. *How to Detect and Count Objects in Polygon Zone.* https://github.com/roboflow/notebooks/blob/main/notebooks/how-to-detect-and-count-objects-in-polygon-zone.ipynb
11. Roboflow Supervision. *Time in Zone (ROI) Example.* https://github.com/roboflow/supervision/tree/develop/examples/time_in_zone
12.  [Report: Traffic Collision and Accident Prevention Detection using Deep Learning & IOT](https://drive.google.com/file/d/1RIXk25xOOliYHvYM6kX8Mgh2j2Tql1AU/view?usp=sharing)
13. [Presenation of the Project](https://drive.google.com/file/d/1jmyutvZbrlSyiDAUxqbjByGppgKFw-UH/view?usp=sharing)

### üì∫ Tutorial References

| Tutorial | Link |
|----------|------|
| Traffic Speed Estimation & Vehicle Tracking | [YouTube](https://www.youtube.com/watch?v=uWP6UjDeZvY&t=39) |
| Retail Counter / ROI People Counting | [YouTube](https://www.youtube.com/watch?v=hAWpsIuem10&t=1519s) |
| People Counting in Queues with Object Detection | [YouTube](https://www.youtube.com/watch?v=t61EqN8ZwDQ) |
| YOLOv8 + DeepSORT Pedestrian Detection | [YouTube](https://www.youtube.com/watch?v=jIRRuGN0j5E) |
| Distance Calculation with Ultralytics YOLOv8 | [YouTube](https://www.youtube.com/watch?v=LE8am1QoVn4) |

---



<div align="center">

**‚≠ê If this project helped you or inspired your work, please give it a star! ‚≠ê**

*Made with ‚ù§Ô∏è for Community Service | Redhills, Chennai, India üáÆüá≥*

*¬© 2025 ‚Äî Arokiya Nithish J*

</div>
